## План работы по улучшению распознавания текста и обучения Tesseract

### Оптимизация шрифтов для распознавания

- [ ] Удалить неэффективные шрифты для распознавания текстов:
    - [ ] Отсеять моноширинные шрифты, не подходящие для распознавания книг.

### Подготовка датасета для обучения Tesseract

- [ ] Разработать DAG для сборки датасета:
    - [ ] Группировать данные по сочетаниям символов.
        - [x] Создать Jupyter ноутбук для сборки датасета.
        - [x] Создать Jupyter ноутбук для сборки слов по сравнению с эталонными данными.

### Генерация изображений для обучения

- [x] Разработать DAG для генерации изображений.

### Процесс обучения Tesseract

- [x] Разработать DAG для процесса обучения.

### Тестирование и анализ результатов

- [x] Разработать DAG для тестирования обученной модели Tesseract на тестовой книге.
- [x] Составить отчёт по результатам тестирования.
- [x] Сравнение результатов работы модели с эталонными данными.

### Метрики качества

- [ ] Добавить метрики для оценки качества распознавания на уровне слов:
    - [ ] Включить колонку в CSV-файл, указывающую наличие слова в словаре.
    - [ ] Добавить проверку слов при помощи спеллчекера и токенизатора.

### Расширение словаря

- [ ] Разработать DAG для расширения словаря:
    - [ ] Установить пороги confidence для добавления слов после проверки спеллчекером и наличия в нескольких
      источниках.

### Улучшение .hocr файлов

- [ ] Разработать DAG для оптимизации .hocr файлов:
    - [ ] Добавить график для каждой страницы.
    - [ ] Обеспечить возможность просмотра изображений по координатам bounding box.
    - [ ] Реализовать функционал отчетов для сбора и экспорта слов в инструменты проверки и разметки.

### Сбор данных для обучения

- [ ] Собрать разнообразный PDF-материал:
    - [ ] Использовать книги с различными шрифтами и качеством сканирования.

### Шрифты и синтетические данные

- [ ] Собрать расширенный набор шрифтов:
    - [ ] Собрать "книжные" шрифты для обучения.
- [ ] Экспериментировать с генерацией синтетических данных:
    - [ ] Создать синтетические данные для обучения на основе токенов.

## Web сервис

- [ ] Перенести логику обработки скана книги в Airflow
    - [ ] Пересмотреть постобработку скана через готовые инструменты
- [ ] Интегрировать Airflow с Django сервисом для просмотра результатов в веб-интерфейсе
    - [ ] Настроить запуск DAG после загрузки книги в сервис
    - [ ] Добавить возможность выбора модели для прогона через веб-интерфейс
    - [ ] Составить сводную таблицу по моделям (шрифты, текст, метрики)
        - [ ] Обеспечить возможность скачивания модели и датасета
        - [ ] Визуализировать графики и таблицы слов по моделям, выделить слабые места

- [ ] Создать инструмент для проверки/разметки соответствия image box - text
    - [ ] Добавлять отвалидированные данные в обучающий датасет

## Сбор данных для перевода

### Сбор переводов силами сообщества

- [ ] Создать раздел в веб-сервисе для пополнения базы переводов Tatoeba.

### Попытка сбора переводов из словаря

- [ ] Обучить модель на тексте с пропущенными словами для спеллчекера.
- [ ] Доделать инструмент для разметки слов по частям речи.
- [ ] Создать инструмент для лемматизации слов.
- [ ] Разработать инструмент для поиска канонической формы слов.
    - [ ] Собрать префиксы и суффиксы для сохранения смысла слов при лемматизации.
- [ ] Разработать инструмент для поиска синонимов.
- [ ] Добавить кабардино-черкесский язык в Spacy.
- [ ] Собрать переводы по канонической форме слова из билингвальных словарей.
- [ ] Создать пайплайн для сбора перевода предложений с кабардино-черкесского на английский.

### Сбор данных через машинный перевод

- [ ] Собрать корпус параллельных текстов.
    - [ ] Собрать переводы из книг.
- [ ] Обучить модель машинного перевода.
