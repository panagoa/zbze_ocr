{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-18T22:17:34.309556Z",
     "start_time": "2023-11-18T22:17:34.288231Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "direct_object_prefix = r'(?P<direct_object_prefix>у|б|ф|в|д|т|с|з|я|м|)'  # префикс прямого объекта\n",
    "indirect_object_prefix = r'(?P<indirect_object_prefix>а|ы|э|е|)'  # префикс косвенного объекта\n",
    "action_direction = r'(?P<action_direction>къу|къэ|къы|къ|ды|)'  # Направление действия\n",
    "category1 = r'(?P<category1>щы|)'  # Категория 1 (например, определенная грамматическая категория)\n",
    "version_category = r'(?P<version_category>хуа|хуэ|ху|)'  # Категория версии\n",
    "indirect_object_prefix2 = r'(?P<indirect_object_prefix2>зы|зэ|зо|во|до|дэ|хэ|)'  # префикс косвенного объекта (повторно)\n",
    "category2 = r'(?P<category2>рызэ|)'  # Категория 2\n",
    "category3 = r'(?P<category3>ремы|ре|рызы|ры|рэ|рэ|ра|ро|)'  # Категория 3\n",
    "affix1 = r'(?P<affix1>с|з|п|б|и|т|д|я|йа|а|е|)'  # префикс 1\n",
    "version_category_repeat = r'(?P<version_category_repeat>хуа|хуэ|ху|)'  # Повторение категории версии\n",
    "affix2 = r'(?P<affix2>хы|ха|x|)'  # префикс 2\n",
    "version_category2 = r'(?P<version_category2>фӀэ|фI|ф|)'  # Вторая категория версии\n",
    "category4 = r'(?P<category4>гъэ|)'  # Категория 4\n",
    "affix3 = r'(?P<affix3>е|с|з|о|вэ|в|зы|ды|дэ|де|ди|да|до|т|)'  # префикс 3\n",
    "subject_prefix = r'(?P<subject_prefix>з|б|и|д|в|я|йа|а|ри|ра|ре|ры|)'  # префикс субъекта\n",
    "affix4 = r'(?P<affix4>ы|о|э|)'  # префикс 4\n",
    "root_morpheme_0 = r'(?P<root_morpheme_0>.*?)'  # корневая морфема\n",
    "negation_prefix = r'(?P<negation_prefix>мы|)'  # префикс отрицания\n",
    "causative_prefix = r'(?P<causative_prefix>гъэ|)'  # каузативный префикс\n",
    "root_morpheme_1 = r'(?P<root_morpheme_1>.*?)'  # корневая морфема\n",
    "affix5 = r'(?P<affix5>хь|)'  # суффикс 5\n",
    "returned_affix = r'(?P<returned_affix>ыж|жы|жа|ж|)'  # возвратный суффикс\n",
    "affix7 = r'(?P<affix7>ы|э|а|)'  # суффикс 7\n",
    "possibility_suffix = r'(?P<possibility_suffix>ф|)'  # суффикс возможности действия\n",
    "affix8 = r'(?P<affix8>т|)'  # суффикс 8\n",
    "past_tense_suffix = r'(?P<past_tense_suffix>ах|а|х|)'  # суффикс прошедшего времени\n",
    "various_endings = r'(?P<various_endings>ын|эн|нщ|ащ|ущ|ыж|жы|эжу|эж|ат|эм|ар|ам|э)'\n",
    "verb_2_noun_end = r'(?P<verb_2_noun_end>гъэ|гъ)'  # окончание глагола в существительное  \n",
    "additional1 = r'(?P<additional1>ау|)'  # Дополнительная часть 1\n",
    "affix9 = r'(?P<affix9>ы|у|а|)'  # Суффикс 9\n",
    "additional2 = r'(?P<additional2>фы|)'  # Дополнительная часть 2\n",
    "future_tense_suffix = r'(?P<future_tense_suffix>щ|р|м|)'  # суффикс будущего времени\n",
    "large_affix = r'(?P<large_affix>шхуэ)'  # суффикс увеличения\n",
    "absence_affix = r'(?P<absence_affix>ншэ)'  # суффикс отсутствия\n",
    "multiple_affix = r'(?P<multiple_affix>хэ|)'  # множественный суффикс\n",
    "good_affix = r'(?P<good_affix>фIэ)'  # суффикс отсутствия\n",
    "head_affix = r'(?P<head_affix>щхьэ)'  # суффикс отсутствия\n",
    "affix10 = r'(?P<affix10>ы|у|а|э|)'  # Суффикс 10\n",
    "future_tense_suffix2 = r'(?P<future_tense_suffix2>ну|н|)'  # второй суффикс будущего времени\n",
    "negation_form = r'(?P<negation_form>къым)'  # форма отрицания\n",
    "additional3 = r'(?P<additional3>эрэ|ра|)'  # Дополнительная часть 3\n",
    "affix11 = r'(?P<affix11>щ|р|м|т)'  # Суффикс 11\n",
    "additional4 = r'(?P<additional4>кӀ|)'  # Дополнительная часть 4\n",
    "affix12 = r'(?P<affix12>и|э|)'  # Суффикс 12\n",
    "remaining_chars = r'(?P<remaining_chars>\\w*)'  # оставшиеся символы\n",
    "\n",
    "fallback_regexp = re.compile(\n",
    "    r'(?P<direct_object_prefix>у|б|ф|в|д|т|с|з|я|м|)?'  # префикс прямого объекта\n",
    "    r'(?P<indirect_object_prefix>а|ы|э|е|)?'  # префикс косвенного объекта\n",
    "    r'(?P<action_direction>къу|къэ|къы|къ|ды|)?'  # Направление действия\n",
    "    r'(?P<category1>щы|)?'  # Категория 1 (например, определенная грамматическая категория)\n",
    "    r'(?P<version_category>хуа|хуэ|ху|)?'  # Категория версии\n",
    "    r'(?P<indirect_object_prefix2>зы|зэ|зо|во|до|дэ|хэ|)?'  # префикс косвенного объекта (повторно)\n",
    "    r'(?P<category2>рызэ|)?'  # Категория 2\n",
    "    r'(?P<category3>ремы|ре|рызы|ры|рэ|ро|)?'  # Категория 3\n",
    "    r'(?P<affix1>с|з|п|б|и|т|д|я|йа|а|е|)?'  # префикс 1\n",
    "    r'(?P<version_category_repeat>хуа|хуэ|ху|)?'  # Повторение категории версии\n",
    "    r'(?P<affix2>хы|ха|x|)?'  # префикс 2\n",
    "    r'(?P<version_category2>фӀэ|фI|ф|)?'  # Вторая категория версии\n",
    "    r'(?P<category4>гъэ|)?'  # Категория 4\n",
    "    r'(?P<affix3>е|с|з|о|вэ|в|зы|ды|дэ|де|ди|да|до|т|)?'  # префикс 3\n",
    "    r'(?P<subject_prefix>з|б|и|д|в|я|йа|а|ри|ра|ре|ры|)?'  # префикс субъекта\n",
    "    r'(?P<affix4>ы|о|э|)?'  # префикс 4\n",
    "    r'(?P<root_morpheme_0>.*?)'  # корневая морфема\n",
    "    r'(?P<negation_prefix>мы|)?'  # префикс отрицания\n",
    "    r'(?P<causative_prefix>гъэ|)?'  # каузативный префикс\n",
    "    r'(?P<root_morpheme_1>.*?)'  # корневая морфема\n",
    "    r'(?P<affix5>хь|)?'  # суффикс 5\n",
    "    r'(?P<returned_affix>ыж|жы|жа|ж|)?'  # возвратный суффикс\n",
    "    r'(?P<affix7>ы|э|а|)?'  # суффикс 7\n",
    "    r'(?P<possibility_suffix>ф|)?'  # суффикс возможности действия\n",
    "    r'(?P<affix8>т|)?'  # суффикс 8\n",
    "    r'(?P<past_tense_suffix>ах|а|х|)?'  # суффикс прошедшего времени\n",
    "    r'(?P<various_endings>ын|эн|нщ|ащ|ущ|ыж|жы|эжу|эж|ат|эм|ар|ам|э|гъэ|гъ)?'\n",
    "    r'(?P<various_end>ын$|эн$|нщ$|ащ$|ущ$|ыж$|жы$|эжу$|эж$|ат$|эм$|ар$|ам$|э$|гъэ$|гъ$)?'\n",
    "    r'(?P<additional1>ау|)?'  # Дополнительная часть 1\n",
    "    r'(?P<affix9>ы|у|а|)?'  # Суффикс 9\n",
    "    r'(?P<additional2>фы|)?'  # Дополнительная часть 2\n",
    "    r'(?P<future_tense_suffix>щ|р|м|)?'  # суффикс будущего времени\n",
    "    r'(?P<large_affix>шхуэ|)?'  # суффикс увеличения\n",
    "    r'(?P<absence_affix>ншэ|)?'  # суффикс отсутствия\n",
    "    r'(?P<multiple_affix>хэ|)?'  # множественный суффикс\n",
    "    r'(?P<good_affix>фIэ|)?'  # суффикс отсутствия\n",
    "    r'(?P<head_affix>щхьэ|)?'  # суффикс отсутствия\n",
    "    r'(?P<affix10>ы|у|а|э|)?'  # Суффикс 10\n",
    "    r'(?P<future_tense_suffix2>ну|н|)?'  # второй суффикс будущего времени\n",
    "    r'(?P<negation_form>къым|)?'  # форма отрицания\n",
    "    r'(?P<additional3>эрэ|ра|)?'  # Дополнительная часть 3\n",
    "    r'(?P<affix11>щ|р|м|т|)?'  # Суффикс 11\n",
    "    r'(?P<affix11_end>щ$|р$|м$|т$|)?'  # Суффикс 11\n",
    "    r'(?P<additional4>кӀ|)?'  # Дополнительная часть 4\n",
    "    r'(?P<affix12>и$|э$|)?'  # Суффикс 12\n",
    "    # r'(?P<remaining_chars>\\w*)'  # оставшиеся символы\n",
    ")\n",
    "\n",
    "ordered_part_name = [\n",
    "    'direct_object_prefix',\n",
    "    'indirect_object_prefix',\n",
    "    'action_direction',\n",
    "    'category1',\n",
    "    'version_category',\n",
    "    'indirect_object_prefix2',\n",
    "    'category2',\n",
    "    'category3',\n",
    "    'affix1',\n",
    "    'version_category_repeat',\n",
    "    'affix2',\n",
    "    'version_category2',\n",
    "    'category4',\n",
    "    'affix3',\n",
    "    'subject_prefix',\n",
    "    'affix4',\n",
    "    'root_morpheme_0',\n",
    "    'negation_prefix',\n",
    "    'causative_prefix',\n",
    "    'root_morpheme_1',\n",
    "    'affix5',\n",
    "    'returned_affix',\n",
    "    'affix7',\n",
    "    'possibility_suffix',\n",
    "    'affix8',\n",
    "    'past_tense_suffix',\n",
    "    'various_endings',\n",
    "    'verb_2_noun_end',\n",
    "    'additional1',\n",
    "    'affix9',\n",
    "    'additional2',\n",
    "    'future_tense_suffix',\n",
    "    'large_affix',\n",
    "    'absence_affix',\n",
    "    'good_affix',\n",
    "    'head_affix',\n",
    "    'multiple_affix',\n",
    "    'affix10',\n",
    "    'future_tense_suffix2',\n",
    "    'negation_form',\n",
    "    'additional3',\n",
    "    'affix11',\n",
    "    'additional4',\n",
    "    'affix12',\n",
    "    'remaining_chars',\n",
    "]\n",
    "\n",
    "\n",
    "class KabardianStemmer:\n",
    "    regexp_map = [\n",
    "        ('diaf11', re.compile(\n",
    "            direct_object_prefix + indirect_object_prefix + action_direction +\n",
    "            root_morpheme_1 + future_tense_suffix2 + affix11 + '$'\n",
    "        ), False),\n",
    "        ('diar1112', re.compile(\n",
    "            direct_object_prefix + indirect_object_prefix + action_direction +\n",
    "            root_morpheme_1 + returned_affix + affix11 + affix12 + '$'\n",
    "        ), False),\n",
    "        ('lg', re.compile(\n",
    "            root_morpheme_1 + large_affix + '$'\n",
    "        ), False),\n",
    "        ('rl11', re.compile(\n",
    "            root_morpheme_1 + large_affix + affix11 + '$'\n",
    "        ), False),\n",
    "        ('abs', re.compile(\n",
    "            root_morpheme_1 + absence_affix + '$'\n",
    "        ), False),\n",
    "        ('av_ng', re.compile(\n",
    "            action_direction + version_category + affix1 + affix3 + root_morpheme_1 + negation_form + '$'\n",
    "        ), False),\n",
    "        ('a13ng', re.compile(\n",
    "            action_direction + affix1 + affix3 + subject_prefix + root_morpheme_1 + negation_form + '$'\n",
    "        ), False),\n",
    "        ('810ng', re.compile(\n",
    "            root_morpheme_1 + affix8 + affix10 + negation_form + '$'\n",
    "        ), False),\n",
    "        ('ng', re.compile(\n",
    "            root_morpheme_1 + negation_form + '$'\n",
    "        ), False),\n",
    "        ('gm11', re.compile(\n",
    "            root_morpheme_1 + good_affix + multiple_affix + affix11 + '$'\n",
    "        ), False),\n",
    "        ('v2nm11', re.compile(\n",
    "            root_morpheme_1 + verb_2_noun_end + multiple_affix + affix11 + '$'\n",
    "        ), False),\n",
    "        ('am1112', re.compile(\n",
    "            action_direction + root_morpheme_1 + multiple_affix + affix11 + affix12 + '$'\n",
    "        ), False),\n",
    "        ('m1112', re.compile(\n",
    "            root_morpheme_1 + multiple_affix + affix11 + affix12 + '$'\n",
    "        ), False),\n",
    "        ('aim311', re.compile(\n",
    "            action_direction + indirect_object_prefix2 + category3 + root_morpheme_1 + multiple_affix + affix11 + '$'\n",
    "        ), False),\n",
    "        ('dcm11', re.compile(\n",
    "            direct_object_prefix + causative_prefix + root_morpheme_1 + multiple_affix + affix11 + '$'\n",
    "        ), False),\n",
    "        ('m11', re.compile(\n",
    "            root_morpheme_1 + multiple_affix + affix11 + '$'\n",
    "        ), False),\n",
    "        ('a13c1011', re.compile(\n",
    "            action_direction + affix1 + affix3 + subject_prefix + causative_prefix + root_morpheme_1 + affix10 + affix11 + '$'\n",
    "        ), False),\n",
    "        ('a131011', re.compile(\n",
    "            action_direction + affix1 + affix3 + root_morpheme_1 + affix10 + affix11 + '$'\n",
    "        ), False),\n",
    "        ('a1011', re.compile(\n",
    "            action_direction + root_morpheme_1 + affix10 + affix11 + '$'\n",
    "        ), False),\n",
    "        ('dnc10', re.compile(\n",
    "            direct_object_prefix + negation_prefix + causative_prefix + root_morpheme_1 + affix10 + '$'\n",
    "        ), False),\n",
    "        ('din', re.compile(\n",
    "            direct_object_prefix + indirect_object_prefix + root_morpheme_1 + negation_form + '$'\n",
    "        ), False),\n",
    "        ('dii9f10', re.compile(\n",
    "            direct_object_prefix + indirect_object_prefix + indirect_object_prefix2 + root_morpheme_1 + affix9\n",
    "            + future_tense_suffix + affix10 + '$'\n",
    "        ), False),\n",
    "        ('dii10', re.compile(\n",
    "            direct_object_prefix + indirect_object_prefix + indirect_object_prefix2 + root_morpheme_1 + affix10 + '$'\n",
    "        ), False),\n",
    "        ('di10', re.compile(\n",
    "            direct_object_prefix + indirect_object_prefix + root_morpheme_1 + affix10 + '$'\n",
    "        ), False),\n",
    "        ('di11', re.compile(\n",
    "            direct_object_prefix + indirect_object_prefix + root_morpheme_1 + affix11 + '$'\n",
    "        ), False),\n",
    "        ('ca11', re.compile(\n",
    "            category1 + affix1 + root_morpheme_1 + affix11 + '$'\n",
    "        ), False),\n",
    "        ('cr11', re.compile(\n",
    "            root_morpheme_1 + returned_affix + affix11 + '$'\n",
    "        ), False),\n",
    "        ('cg11', re.compile(\n",
    "            root_morpheme_1 + good_affix + affix11 + '$'\n",
    "        ), False),\n",
    "        ('h11', re.compile(\n",
    "            root_morpheme_1 + head_affix + affix11 + '$'\n",
    "        ), False),\n",
    "\n",
    "        # ('c11', re.compile(\n",
    "        #     category1 + root_morpheme_1 + r'(?P<affix11>щ|р|м|т)' + '$'\n",
    "        # )),\n",
    "        # ('11', re.compile(\n",
    "        #     root_morpheme_1 + affix11 + '$'\n",
    "        # )),\n",
    "        # ('3', re.compile(\n",
    "        #     indirect_object_prefix + category4 + root_morpheme_1 + various_endings + '$'\n",
    "        # )),\n",
    "    ]\n",
    "\n",
    "    def __init__(self, min_len=4, group_root_index=18):\n",
    "        self.min_len = min_len\n",
    "        self.group_root_index = group_root_index\n",
    "\n",
    "    def get_groups(self, word, skip_disabled=False):\n",
    "        word = word.lower().replace('i', 'I')\n",
    "        if len(word) < self.min_len:\n",
    "            return None, None, 'too_short'\n",
    "\n",
    "        name, match = None, None\n",
    "        for name, regexp, is_enable in self.regexp_map:\n",
    "            if skip_disabled and not is_enable:\n",
    "                continue\n",
    "\n",
    "            match = regexp.match(word)\n",
    "            if match and all(match.groups()):\n",
    "                break\n",
    "\n",
    "        if not match:\n",
    "            match = fallback_regexp.match(word)\n",
    "            if match:\n",
    "                part_joined = ':'.join([part for part in ordered_part_name if match.groupdict().get(part)])\n",
    "                name = f'all_part:{part_joined}'\n",
    "\n",
    "        if not match:\n",
    "            return None, None, name\n",
    "\n",
    "        return match.groups(), match.groupdict(), name\n",
    "\n",
    "    def stem(self, word):\n",
    "        groups, groupdict, name = self.get_groups(word)\n",
    "        if not groups:\n",
    "            return word, None\n",
    "\n",
    "        root_0 = groupdict.get('root_morpheme_0') or ''\n",
    "        root_1 = groupdict.get('root_morpheme_1') or ''\n",
    "        root = root_0 + root_1\n",
    "\n",
    "        negation_prefix = groupdict.get('negation_prefix')\n",
    "        if negation_prefix:\n",
    "            print('negation_prefix', negation_prefix, groups[:groups.index(negation_prefix)])\n",
    "            return ''.join(groups[:groups.index(negation_prefix)]) + root\n",
    "        elif len(root) >= self.min_len:\n",
    "            return root\n",
    "        else:\n",
    "            return self.complicate(root, groups)\n",
    "\n",
    "    def complicate(self, stem, groups):\n",
    "        groups_list = list(groups)\n",
    "\n",
    "        right_affix = self._process_affixes(groups_list, \"right\")\n",
    "        left_affix = self._process_affixes(groups_list, \"left\")\n",
    "\n",
    "        complicate_stem = (left_affix or '') + stem + (right_affix or '')\n",
    "        return complicate_stem if len(complicate_stem) >= self.min_len else stem\n",
    "\n",
    "    def _process_affixes(self, groups_list, direction):\n",
    "        if direction == \"right\":\n",
    "            start, end, step = self.group_root_index + 1, len(groups_list), 1\n",
    "        else:  # direction == \"left\"\n",
    "            start, end, step = self.group_root_index - 1, 0, -1\n",
    "\n",
    "        for index in range(start, end, step):\n",
    "            if groups_list[index]:\n",
    "                groups_list[index] = None\n",
    "                return groups_list[index]\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('diaf11',\n",
      "  re.compile('(?P<direct_object_prefix>у|б|ф|в|д|т|с|з|я|м|)(?P<indirect_object_prefix>а|ы|э|е|)(?P<action_direction>къу|къэ|къы|къ|ды|)(?P<root_morpheme_1>.*?)(?P<future_tense_suffix2>ну|н|)(?P<affix11>щ|р|м|т)$'),\n",
      "  False),\n",
      " ('diar1112',\n",
      "  re.compile('(?P<direct_object_prefix>у|б|ф|в|д|т|с|з|я|м|)(?P<indirect_object_prefix>а|ы|э|е|)(?P<action_direction>къу|къэ|къы|къ|ды|)(?P<root_morpheme_1>.*?)(?P<returned_affix>ыж|жы|жа|ж|)(?P<affix11>щ|р|м|т)(?),\n",
      "  False),\n",
      " ('lg', re.compile('(?P<root_morpheme_1>.*?)(?P<large_affix>шхуэ)$'), False),\n",
      " ('rl11',\n",
      "  re.compile('(?P<root_morpheme_1>.*?)(?P<large_affix>шхуэ)(?P<affix11>щ|р|м|т)$'),\n",
      "  False),\n",
      " ('abs', re.compile('(?P<root_morpheme_1>.*?)(?P<absence_affix>ншэ)$'), False),\n",
      " ('av_ng',\n",
      "  re.compile('(?P<action_direction>къу|къэ|къы|къ|ды|)(?P<version_category>хуа|хуэ|ху|)(?P<affix1>с|з|п|б|и|т|д|я|йа|а|е|)(?P<affix3>е|с|з|о|вэ|в|зы|ды|дэ|де|ди|да|до|т|)(?P<root_morpheme_1>.*?)(?P<negation_form>к),\n",
      "  False),\n",
      " ('a13ng',\n",
      "  re.compile('(?P<action_direction>къу|къэ|къы|къ|ды|)(?P<affix1>с|з|п|б|и|т|д|я|йа|а|е|)(?P<affix3>е|с|з|о|вэ|в|зы|ды|дэ|де|ди|да|до|т|)(?P<subject_prefix>з|б|и|д|в|я|йа|а|ри|ра|ре|ры|)(?P<root_morpheme_1>.*?)(?P),\n",
      "  False),\n",
      " ('810ng',\n",
      "  re.compile('(?P<root_morpheme_1>.*?)(?P<affix8>т|)(?P<affix10>ы|у|а|э|)(?P<negation_form>къым)$'),\n",
      "  False),\n",
      " ('ng', re.compile('(?P<root_morpheme_1>.*?)(?P<negation_form>къым)$'), False),\n",
      " ('gm11',\n",
      "  re.compile('(?P<root_morpheme_1>.*?)(?P<good_affix>фIэ)(?P<multiple_affix>хэ|)(?P<affix11>щ|р|м|т)$'),\n",
      "  False),\n",
      " ('v2nm11',\n",
      "  re.compile('(?P<root_morpheme_1>.*?)(?P<verb_2_noun_end>гъэ|гъ)(?P<multiple_affix>хэ|)(?P<affix11>щ|р|м|т)$'),\n",
      "  False),\n",
      " ('am1112',\n",
      "  re.compile('(?P<action_direction>къу|къэ|къы|къ|ды|)(?P<root_morpheme_1>.*?)(?P<multiple_affix>хэ|)(?P<affix11>щ|р|м|т)(?P<affix12>и|э|)$'),\n",
      "  False),\n",
      " ('m1112',\n",
      "  re.compile('(?P<root_morpheme_1>.*?)(?P<multiple_affix>хэ|)(?P<affix11>щ|р|м|т)(?P<affix12>и|э|)$'),\n",
      "  False),\n",
      " ('aim311',\n",
      "  re.compile('(?P<action_direction>къу|къэ|къы|къ|ды|)(?P<indirect_object_prefix2>зы|зэ|зо|во|до|дэ|хэ|)(?P<category3>ремы|ре|рызы|ры|рэ|рэ|ра|ро|)(?P<root_morpheme_1>.*?)(?P<multiple_affix>хэ|)(?P<affix11>щ|р|м|т),\n",
      "  False),\n",
      " ('dcm11',\n",
      "  re.compile('(?P<direct_object_prefix>у|б|ф|в|д|т|с|з|я|м|)(?P<causative_prefix>гъэ|)(?P<root_morpheme_1>.*?)(?P<multiple_affix>хэ|)(?P<affix11>щ|р|м|т)$'),\n",
      "  False),\n",
      " ('m11',\n",
      "  re.compile('(?P<root_morpheme_1>.*?)(?P<multiple_affix>хэ|)(?P<affix11>щ|р|м|т)$'),\n",
      "  False),\n",
      " ('a13c1011',\n",
      "  re.compile('(?P<action_direction>къу|къэ|къы|къ|ды|)(?P<affix1>с|з|п|б|и|т|д|я|йа|а|е|)(?P<affix3>е|с|з|о|вэ|в|зы|ды|дэ|де|ди|да|до|т|)(?P<subject_prefix>з|б|и|д|в|я|йа|а|ри|ра|ре|ры|)(?P<causative_prefix>гъэ|)(),\n",
      "  False),\n",
      " ('a131011',\n",
      "  re.compile('(?P<action_direction>къу|къэ|къы|къ|ды|)(?P<affix1>с|з|п|б|и|т|д|я|йа|а|е|)(?P<affix3>е|с|з|о|вэ|в|зы|ды|дэ|де|ди|да|до|т|)(?P<root_morpheme_1>.*?)(?P<affix10>ы|у|а|э|)(?P<affix11>щ|р|м|т)$'),\n",
      "  False),\n",
      " ('a1011',\n",
      "  re.compile('(?P<action_direction>къу|къэ|къы|къ|ды|)(?P<root_morpheme_1>.*?)(?P<affix10>ы|у|а|э|)(?P<affix11>щ|р|м|т)$'),\n",
      "  False),\n",
      " ('dnc10',\n",
      "  re.compile('(?P<direct_object_prefix>у|б|ф|в|д|т|с|з|я|м|)(?P<negation_prefix>мы|)(?P<causative_prefix>гъэ|)(?P<root_morpheme_1>.*?)(?P<affix10>ы|у|а|э|)$'),\n",
      "  False),\n",
      " ('din',\n",
      "  re.compile('(?P<direct_object_prefix>у|б|ф|в|д|т|с|з|я|м|)(?P<indirect_object_prefix>а|ы|э|е|)(?P<root_morpheme_1>.*?)(?P<negation_form>къым)$'),\n",
      "  False),\n",
      " ('dii9f10',\n",
      "  re.compile('(?P<direct_object_prefix>у|б|ф|в|д|т|с|з|я|м|)(?P<indirect_object_prefix>а|ы|э|е|)(?P<indirect_object_prefix2>зы|зэ|зо|во|до|дэ|хэ|)(?P<root_morpheme_1>.*?)(?P<affix9>ы|у|а|)(?P<future_tense_suffix>щ),\n",
      "  False),\n",
      " ('dii10',\n",
      "  re.compile('(?P<direct_object_prefix>у|б|ф|в|д|т|с|з|я|м|)(?P<indirect_object_prefix>а|ы|э|е|)(?P<indirect_object_prefix2>зы|зэ|зо|во|до|дэ|хэ|)(?P<root_morpheme_1>.*?)(?P<affix10>ы|у|а|э|)$'),\n",
      "  False),\n",
      " ('di10',\n",
      "  re.compile('(?P<direct_object_prefix>у|б|ф|в|д|т|с|з|я|м|)(?P<indirect_object_prefix>а|ы|э|е|)(?P<root_morpheme_1>.*?)(?P<affix10>ы|у|а|э|)$'),\n",
      "  False),\n",
      " ('di11',\n",
      "  re.compile('(?P<direct_object_prefix>у|б|ф|в|д|т|с|з|я|м|)(?P<indirect_object_prefix>а|ы|э|е|)(?P<root_morpheme_1>.*?)(?P<affix11>щ|р|м|т)$'),\n",
      "  False),\n",
      " ('ca11',\n",
      "  re.compile('(?P<category1>щы|)(?P<affix1>с|з|п|б|и|т|д|я|йа|а|е|)(?P<root_morpheme_1>.*?)(?P<affix11>щ|р|м|т)$'),\n",
      "  False),\n",
      " ('cr11',\n",
      "  re.compile('(?P<root_morpheme_1>.*?)(?P<returned_affix>ыж|жы|жа|ж|)(?P<affix11>щ|р|м|т)$'),\n",
      "  False),\n",
      " ('cg11',\n",
      "  re.compile('(?P<root_morpheme_1>.*?)(?P<good_affix>фIэ)(?P<affix11>щ|р|м|т)$'),\n",
      "  False),\n",
      " ('h11',\n",
      "  re.compile('(?P<root_morpheme_1>.*?)(?P<head_affix>щхьэ)(?P<affix11>щ|р|м|т)$'),\n",
      "  False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": "(('б',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  None,\n  None,\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  '',\n  ''),\n {'direct_object_prefix': 'б',\n  'indirect_object_prefix': '',\n  'action_direction': '',\n  'category1': '',\n  'version_category': '',\n  'indirect_object_prefix2': '',\n  'category2': '',\n  'category3': '',\n  'affix1': '',\n  'version_category_repeat': '',\n  'affix2': '',\n  'version_category2': '',\n  'category4': '',\n  'affix3': '',\n  'subject_prefix': '',\n  'affix4': '',\n  'root_morpheme_0': '',\n  'negation_prefix': '',\n  'causative_prefix': '',\n  'root_morpheme_1': '',\n  'affix5': '',\n  'returned_affix': '',\n  'affix7': '',\n  'possibility_suffix': '',\n  'affix8': '',\n  'past_tense_suffix': '',\n  'various_endings': None,\n  'various_end': None,\n  'additional1': '',\n  'affix9': '',\n  'additional2': '',\n  'future_tense_suffix': '',\n  'large_affix': '',\n  'absence_affix': '',\n  'multiple_affix': '',\n  'good_affix': '',\n  'head_affix': '',\n  'affix10': '',\n  'future_tense_suffix2': '',\n  'negation_form': '',\n  'additional3': '',\n  'affix11': '',\n  'affix11_end': '',\n  'additional4': '',\n  'affix12': ''},\n 'all_part:direct_object_prefix')"
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "stemmer = KabardianStemmer()\n",
    "pprint(stemmer.regexp_map)\n",
    "\n",
    "q = 'Бгырыпхым'\n",
    "stemmer.get_groups(q.replace(',', ''))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T22:17:35.709406Z",
     "start_time": "2023-11-18T22:17:35.697024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('../data/tesstrain/kbd/configs/kbd.wordlist', 'r') as f:\n",
    "    words = f.read().split('\\n')\n",
    "\n",
    "words_grouped = [\n",
    "    {name: None for name in ordered_part_name}\n",
    "]\n",
    "\n",
    "for word in sorted(words):\n",
    "    groups, groupdict, name = stemmer.get_groups(word)\n",
    "    if groups:\n",
    "        data = dict(\n",
    "            word=word,\n",
    "            name=name,\n",
    "            **groupdict\n",
    "        )\n",
    "        words_grouped.append(data)\n",
    "\n",
    "df = pd.DataFrame(words_grouped)\n",
    "# special columns\n",
    "df = df[['word'] + ordered_part_name + ['name']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T05:12:58.489820Z",
     "start_time": "2023-11-18T05:12:26.419996Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "outputs": [],
   "source": [
    "df.to_csv('../data/tesstrain/kbd/configs/kbd.wordlist.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-18T05:13:00.063947Z",
     "start_time": "2023-11-18T05:12:58.490135Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
