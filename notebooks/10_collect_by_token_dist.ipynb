{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:53:21.209692Z",
     "start_time": "2023-11-19T20:53:21.172945Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer_uni = Tokenizer.from_file(\n",
    "    os.path.join('../dags/src/spellcheck/data/', 'tokenizer_unigram_5k.json')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "with open('../data/tesstrain/kbd/configs/kbd.wordlist', 'r') as f:\n",
    "    words = f.read().split('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:53:21.827541Z",
     "start_time": "2023-11-19T20:53:21.696224Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import csv\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "\n",
    "\n",
    "def create_token_ng_distribution(words, n=5):\n",
    "    fd = nltk.FreqDist()\n",
    "    ngrams_tokens = defaultdict(list)\n",
    "\n",
    "    for word in sorted(words):\n",
    "        tokens = tokenizer_uni.encode(word).tokens\n",
    "        token_ids = [tokenizer_uni.token_to_id(token) for token in tokens]\n",
    "\n",
    "        ngrams = tuple(nltk.ngrams(tokens, n=n))\n",
    "        fd.update(ngrams)\n",
    "        for ng in ngrams:\n",
    "            ngrams_tokens[ng].append((tokens, token_ids))\n",
    "\n",
    "    os.makedirs('../data/tesstrain/kbd/token_dist', exist_ok=True)\n",
    "    os.makedirs(f'../data/tesstrain/kbd/token_dist/{n}', exist_ok=True)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for ng, freq in tqdm(sorted(fd.items(), key=lambda x: x[1], reverse=True)):\n",
    "        if freq < 10:\n",
    "            break\n",
    "\n",
    "        ng_name = '_'.join(ng)\n",
    "        f_name = f'({freq}){ng_name}'\n",
    "\n",
    "        df_data = []\n",
    "        for _tokens, _token_ids in ngrams_tokens[ng]:\n",
    "            df_data.append({\n",
    "                'ng_name': ng_name,\n",
    "                'q_ng_len': n,\n",
    "                'q': ''.join(ng),\n",
    "                'word_ng_len': len(_tokens),\n",
    "                'word': ''.join(_tokens),\n",
    "                'tokens': '|'.join(_tokens),\n",
    "                'token_ids': '|'.join([str(_id) for _id in _token_ids])\n",
    "            })\n",
    "        data.extend(df_data)\n",
    "\n",
    "        df = pd.DataFrame(df_data)\n",
    "        df.to_csv(f'../data/tesstrain/kbd/token_dist/{n}/{f_name}.csv', index=False, sep=',', quoting=csv.QUOTE_NONE, header=True)\n",
    "    \n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:53:23.018112Z",
     "start_time": "2023-11-19T20:53:23.002232Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 759/1113 [00:07<00:03, 97.83it/s] \n",
      " 30%|███       | 14978/49331 [00:11<00:27, 1267.02it/s]\n",
      " 12%|█▏        | 26218/218569 [00:13<01:37, 1967.41it/s]\n",
      "  5%|▍         | 18067/366593 [00:08<02:36, 2227.57it/s]\n",
      "  2%|▏         | 6945/378005 [00:03<02:48, 2203.63it/s]\n",
      "  1%|          | 1779/280121 [00:00<01:57, 2361.33it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for n in range(1, 7):\n",
    "    data_i = create_token_ng_distribution(words, n=n)\n",
    "    data.extend(data_i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:54:49.473573Z",
     "start_time": "2023-11-19T20:53:24.441559Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.to_csv(f'../data/tesstrain/kbd/token_dist/all.csv', index=False, sep=',', quoting=csv.QUOTE_ALL, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T20:55:03.244304Z",
     "start_time": "2023-11-19T20:54:56.240304Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
