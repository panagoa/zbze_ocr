{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "words = [\n",
    "    \"къеукIуриехыу\",\n",
    "    \"къытехуауэ\",\n",
    "    \"зэрыщыжыпIар\",\n",
    "    \"Жъесыну\",\n",
    "    \"нэужьщ\",\n",
    "    \"зэрынэсу\",\n",
    "    \"ЩIыр\",\n",
    "    \"зэрыпщIэщи\",\n",
    "    \"щIашыжащ\",\n",
    "    \"къыпежьэри\",\n",
    "    \"хуеякъым\",\n",
    "    \"сынэгъэс\",\n",
    "    \"хьэпшып\",\n",
    "    \"тесынри\",\n",
    "    \"НтIэ\",\n",
    "    \"Шыдыгум\",\n",
    "    \"уафэм\",\n",
    "    \"пулеметышэу\",\n",
    "    \"шынагъуэу\",\n",
    "    \"пэшым\",\n",
    "    \"гъунэгъу\",\n",
    "    \"къысхуеину\",\n",
    "    \"пщIыр\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:38:41.014924Z",
     "start_time": "2023-10-23T14:38:41.004467Z"
    }
   },
   "id": "52d7b4c1ce86d1ec"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import os\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "\n",
    "\n",
    "def _get_text_by_lang(book_base_dir, lang):\n",
    "    lang_text_dir = os.path.join(book_base_dir, lang, \"txts\")\n",
    "\n",
    "    lang_text_by_page = []\n",
    "    for text_f in sorted(os.listdir(lang_text_dir)):\n",
    "        with open(os.path.join(lang_text_dir, text_f)) as f:\n",
    "            text = f.read()\n",
    "            lang_text_by_page.append(text)\n",
    "\n",
    "    return lang_text_by_page\n",
    "\n",
    "\n",
    "def extract_diff_words(line_1, line_2):\n",
    "    line_1 = re.sub(r\"[^\\w\\s]\", \"\", line_1)\n",
    "    line_2 = re.sub(r\"[^\\w\\s]\", \"\", line_2)\n",
    "\n",
    "    words1 = line_1.split()\n",
    "    words2 = line_2.split()\n",
    "\n",
    "    sequence_matcher = SequenceMatcher(None, words1, words2)\n",
    "    match = sequence_matcher.get_matching_blocks()\n",
    "\n",
    "    different_words_1 = []\n",
    "    different_words_2 = []\n",
    "\n",
    "    start1 = 0\n",
    "    start2 = 0\n",
    "\n",
    "    for block in match:\n",
    "        different_words_1.extend(words1[start1 : block.a])\n",
    "        different_words_2.extend(words2[start2 : block.b])\n",
    "\n",
    "        start1 = block.a + block.size\n",
    "        start2 = block.b + block.size\n",
    "\n",
    "    return tuple(different_words_1), tuple(different_words_2)\n",
    "\n",
    "\n",
    "def find_diff_words_by_lang(book_base_dir, lang_1, lang_2):\n",
    "    lang_1_text_by_page = _get_text_by_lang(book_base_dir, lang_1)\n",
    "    lang_2_text_by_page = _get_text_by_lang(book_base_dir, lang_2)\n",
    "\n",
    "    if len(lang_1_text_by_page) != len(lang_2_text_by_page):\n",
    "        raise ValueError(\"Text lengths for both languages must be the same.\")\n",
    "\n",
    "    diff_words_1 = []\n",
    "    diff_words_2 = []\n",
    "\n",
    "    for page_i in range(len(lang_1_text_by_page)):\n",
    "        page_text_1 = lang_1_text_by_page[page_i]\n",
    "        page_text_2 = lang_2_text_by_page[page_i]\n",
    "\n",
    "        for line_1, line_2 in zip(page_text_1.splitlines(), page_text_2.splitlines()):\n",
    "            diff_w_1, diff_w_2 = extract_diff_words(line_1, line_2)\n",
    "            diff_words_1.append(diff_w_1)\n",
    "            diff_words_2.append(diff_w_2)\n",
    "\n",
    "    return diff_words_1, diff_words_2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:48:19.347795Z",
     "start_time": "2023-10-23T14:48:19.337412Z"
    }
   },
   "id": "af08de534af097c9"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "_book_base_dir = \"../data/dag_results/pdf_processing/dysche_zhyg.pdf\"\n",
    "_lang_1 = \"kbd_0.229_2995_10800\"\n",
    "_lang_2 = \"kbd_0.009_4360_66700\"\n",
    "_output_file = os.path.join(_book_base_dir, f\"merged_diff_{_lang_1}_vs_{_lang_2}.html\")\n",
    "words_1, words_2 = find_diff_words_by_lang(_book_base_dir, _lang_1, _lang_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:48:20.067532Z",
     "start_time": "2023-10-23T14:48:19.977446Z"
    }
   },
   "id": "8fb8c109f757b67"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([{_lang_1: \" \".join(w1), _lang_2: \" \".join(w2)} for w1, w2 in zip(words_1, words_2)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:08.297190Z",
     "start_time": "2023-10-23T14:58:08.292081Z"
    }
   },
   "id": "c6f3fc040b27a6f8"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "  kbd_0.229_2995_10800 kbd_0.009_4360_66700\n0                                          \n1                                          \n2                    х                  I у\n3                    Ж                    I\n4                                          ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>kbd_0.229_2995_10800</th>\n      <th>kbd_0.009_4360_66700</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>х</td>\n      <td>I у</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ж</td>\n      <td>I</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:08.898061Z",
     "start_time": "2023-10-23T14:58:08.890796Z"
    }
   },
   "id": "c5ac18ad78913ef5"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kbd_ng_0.097_1738_38300.traineddata', 'kbd_ng_0.106_1737_38100.traineddata', 'kbd_ng_0.123_1725_37800.traineddata', 'kbd_ng_0.128_1178_24200.traineddata', 'kbd_ng_0.135_1173_24100.traineddata', 'kbd_ng_0.143_709_13200.traineddata', 'kbd_ng_0.149_703_13000.traineddata', 'kbd_ng_0.156_700_12900.traineddata', 'kbd_ng_0.171_693_12600.traineddata', 'kbd_ng_0.180_690_12500.traineddata', 'kbd_ng_0.185_228_3700.traineddata', 'kbd_ng_0.220_224_3600.traineddata', 'kbd_ng_0.240_222_3500.traineddata', 'kbd_ng_0.261_16_300.traineddata', 'kbd_ng_0.290_12_200.traineddata', 'kbd_ng_0.305_7_100.traineddata']\n"
     ]
    }
   ],
   "source": [
    "best_traineddata_dir = \"/Users/panagoa/PycharmProjects/tesstrain/data/kbd_ng/tessdata_best\"\n",
    "best_traineddata_name = sorted(\n",
    "    os.listdir(best_traineddata_dir),\n",
    "    # key=lambda x: os.path.getmtime(os.path.join(best_traineddata_dir, x)),\n",
    ")[0]\n",
    "print(best_traineddata_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T16:25:20.034376Z",
     "start_time": "2023-10-23T16:25:20.028067Z"
    }
   },
   "id": "7f7cd28601b69e61"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5d1d99909a494f6c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
